{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"augment_single_images.ipynb","provenance":[{"file_id":"https://github.com/aubricot/object_detection_for_image_cropping/blob/master/COLAB_object_detection_for_image_cropping_yolo.ipynb","timestamp":1574693073734}],"private_outputs":true,"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"4Rnwb_rgmJZB","colab_type":"text"},"source":["# Pre-processing and image augmentation for object detection model training and testing datasets\n","---\n","*Last Updated 1 April 2020*   \n","Test and train datasets (images and cropping dimensions) exported from [split_train_test.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/tree/master/object_detection_for_image_cropping/split_train_test.ipynb) are pre-processed and transformed to formatting standards for use with YOLO via Darkflow and SSD and R-FCN object detection models implemented in Tensorflow. All train and test images are also downloaded to Google Drive for future use training and testing.\n","\n","Before reformatting to object detection model standards, training data for each taxon (Coleoptera, Anura, Squamata and Carnivora) is augmented using the [imgaug library](https://github.com/aleju/imgaug). Image augmentation is used to increase training data sample size and diversity to reduce overfitting when training object detection models. Both images and cropping coordinates are augmented. Augmented and original training datasets are then combined before being transformed to object detection model formatting standards.\n","\n","After exporting augmented box coordinates from this notebook, test displaying them using [coordinates_display_test.ipynb](https://github.com/aubricot/computer_vision_with_eol_images/tree/master/object_detection_for_image_cropping/coordinates_display_test.ipynb). If they are not as expected, modify data cleaning steps in the section **Remove out of bounds values from train crops and export results for use with object detection models** for train and test images below until the desired results are achieved. "]},{"cell_type":"markdown","metadata":{"id":"iJz5m4BKmJZD","colab_type":"text"},"source":["## Installs\n","---\n","Install required libraries directly to this Colab notebook."]},{"cell_type":"code","metadata":{"id":"01UXykSJp610","colab_type":"code","colab":{}},"source":["# Install libraries for augmenting and displaying images\n","!pip install imgaug\n","!pip install pillow\n","!pip install scipy==1.1.0"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yWAbU5tW1ONu","colab_type":"code","colab":{}},"source":["# Mount google drive to import/export files\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"nwKdj73Wpnlz","colab_type":"text"},"source":["## Imports   \n","---"]},{"cell_type":"code","metadata":{"id":"QSLXg6G7mJZP","colab_type":"code","colab":{}},"source":["# Change to your training directory within Google Drive\n","%cd drive/My Drive/fall19_smithsonian_informatics/train\n","\n","# For importing/exporting files, working with arrays, etc\n","import pathlib\n","import os\n","import imageio\n","import time\n","import csv\n","import numpy as np\n","import pandas as pd\n","from urllib.request import urlopen\n","from scipy.misc import imread\n","\n","# For augmenting the images and bounding boxes\n","import imgaug as ia\n","import imgaug.augmenters as iaa\n","from imgaug.augmentables.bbs import BoundingBox, BoundingBoxesOnImage\n","\n","# For drawing onto and plotting the images\n","import matplotlib.pyplot as plt\n","import cv2\n","%config InlineBackend.figure_format = 'svg'\n","%matplotlib inline"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"1lMvu5M0oUrY","colab_type":"text"},"source":["### Train images - Run once for each taxon\n","---\n","Run all steps once for each taxon (Coleoptera, Anura, Squamata and Carnivora).\n","Must change names where you see '# TO-DO' (ie. find -> \"carnivora\" and replace with \"coleoptera\""]},{"cell_type":"markdown","metadata":{"id":"cGMDGahzm44x","colab_type":"text"},"source":["#### Augment & download train images to Google Drive  \n","  "]},{"cell_type":"code","metadata":{"id":"OTplhCGC2KR-","colab_type":"code","colab":{}},"source":["urls = 'https://editors.eol.org/other_files/bundle_images/files/images_for_Lepidoptera_20K_breakdown_000001.txt'\n","df1 = pd.read_csv(urls, sep='\\t')\n","df = df1[['eolMediaURL', 'dataObjectVersionID']]\n","print(df.head())"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"P31JjHddVSEm","colab":{}},"source":["# Augment train images and bounding boxes\n","# Then download train images to Google Drive and write new df with updated filenames and paths\n","# Saved train images will be used with bounding box dimensions for future use with the object detection models\n","\n","# Set-up augmentation parameters and write the header of output file crops_train_aug.tsv generated in the next step\n","from imgaug import augmenters as iaa\n","from scipy import misc\n","# Set number of seconds to timeout if image url taking too long to open\n","import socket\n","socket.setdefaulttimeout(10)\n","\n","# Define image augmentation pipeline\n","# modified from https://github.com/aleju/imgaug\n","seq = iaa.Sequential([\n","    iaa.Crop(px=(1, 16), keep_size=False), # crop by 1-16px, resize resulting image to orig dims\n","    iaa.Affine(rotate=(-25, 25)), # rotate -25 to 25 degrees\n","    iaa.GaussianBlur(sigma=(0, 3.0)), # blur using gaussian kernel with sigma of 0-3\n","    iaa.AddToHueAndSaturation((-50, 50), per_channel=True)\n","])\n","\n","# Optional: set seed to make augmentations reproducible across runs, otherwise will be random each time\n","ia.seed(1) \n","\n","# Loop to perform image augmentation for each image in crops\n","# First test on 5 images from crops\n","#for i, row in crops.head(5).iterrows():\n","# Next run on all rows\n","for i, row in df.iloc[100:110].iterrows():\n","\n","  try:\n","    # Import image from url\n","    # Use imread instead of imageio.imread to load images from url and get consistent output type and shape\n","    url = df.at[i, \"eolMediaURL\"]\n","    with urlopen(url) as file:\n","      image = imread(file, mode='RGB')\n","\n","    # Augment image using settings defined above in seq\n","    image_aug = seq.augment(image=image)\n","    \n","    # Define augmentation results needed in exported dataset\n","    pathbase = '/content/drive/My Drive/fall19_smithsonian_informatics/train/out/aug_ims/'\n","    path_aug = pathbase + str(df.dataObjectVersionID[i]) + '_aug' + '.jpg'\n","    filename_aug = str(df.dataObjectVersionID[i]) + '_aug' + '.jpg'\n","    \n","    # Export augmented images to Google Drive\n","    misc.imsave(path_aug, image_aug)\n","    \n","    # Draw augmented bounding box and image\n","    # Only use this for 20-30 images, otherwise comment out\n","    #imagewbox = cv2.rectangle(image_aug, (xmin_aug, ymin_aug), \n","                      #(xmax_aug, ymax_aug), \n","                      #(255, 0, 157), 3) # change box color and thickness\n","    _, ax = plt.subplots(figsize=(10, 10))\n","    ax.imshow(image_aug)\n","    plt.title('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n","        \n","    # Display message to track augmentation process by image\n","    print('{}) Successfully augmented image from {}'.format(format(i+1, '.0f'), url))\n","  \n","  except:\n","    print('{}) Error: check if web address for image from {} is valid'.format(format(i+1, '.0f'), url))"],"execution_count":0,"outputs":[]}]}